## Задание Metric Learning

### TRAIN / VALIDATION
1) Изображения из датасета FruitsAndVegetables хранятся в каталоге data, который состоит из папок train, test, validation.
Скачать архив с изображениями можно по ссылке: https://mega.nz/file/WngHyJaZ#ZetsJTWLhE3WzPcuFVSvPZWkpYcYYx2cBli15JjrJNM
  На всякий случай, был выбран такой способ для скачивания файлов, так как решение с разархивированием не работало
на устройстве.
  Часть изображений была удалена из датасета по причине того, что на них присутствовали сбивающие нейросеть объекты,
объекты других классов, надписи большим шрифтом, посторонние объекты, не относящиеся к Фруктам и Овощам.
2) В датасете 36 классов, некоторые изображения были удалены, поэтому экземпляров одного класса может оказаться
недостаточно для успешной работы модели. В ходе работы скрипта к train изображениям будет применена альбументация, 
результаты применения будут сохранены в новой папке под названием albumentation в каталоге data.
3) В качестве модели для обучения была выбрана ResNet18, градиенты считались для её последних слоев layer4 и fc.
4) В конфиге losses.py перечислены лоссы, используемые при решении данной задачи.
5) Для запуска этапов обучения и валидации модели необходимо запустить скрипт main.py, предварительно установив 
желаемые значения параметров в конфигах в папке configs. Лучшая модель будет сохраняться в папке models.
6) Также во время обучения модели будет создана папка checkpoint, где будут сохраняться промежуточные данные для 
возможности повторного запуска в случае сбоя обучения.


### PREDICT
7) Для того, чтобы сделать предсказание, к объектам какого класса ближе расположен фрукт/овощ на изображении,
необходимо запустить скрипт predict.py, предварительно указав в конфиге predict_config.json все необходимые параметры.
8) По результатам работы predict.py будет создан json файл с содержанием даты и времени в имени, где будет хранится путь 
к входному изображению и результат работы предикта: список наименований классов ближайших k соседей объекта на входном 
изображении.

Репорт с проведенными экспериментами: https://api.wandb.ai/links/vikto0ry/ghx0khf4
Эксперименты проводились с 4 лосс-функциями: SubCenterArcFaceLoss, SphereFaceLoss, CosFaceLoss, ArcFaceLoss. 
Лучшее значение accuracy на валидационном датасете достигается при лосс-функции ArcFaceLoss на 12 эпохе. При этом 
использовался embedding_size=128, batch_size=8 и модель ResNet18. Возможно, при обучении на большем количестве эпох, 
результат бы улучшился, так как тенденции к заметному понижению accuracy не наблюдается, loss же понижается. Худший 
результат наблюдается при лоссе SphereFaceLoss. Оптимальным выбором лосс-функции, таким образом, будет либо ArcFaceLoss, 
либо CosFaceLoss, так как она тоже показала хорошие результаты. 

Пример работы predict.py изображен на картинке predict_example.jpg, расположенной в корневом каталоге. На ней избражены
предсказания 10 ближайших соседей входного изображения.